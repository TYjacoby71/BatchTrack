Yes ‚Äî the duplication is still happening, but now it's not a race condition anymore (good job moving the save outside the loop ‚Äî that fixed the threading issue).The remaining duplication comes from this block inside save_ingredients_csv:python

existing_combinations = set()
if file_exists:
    try:
        with open(filename, 'r', newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                name_category_key = f"{row.get('common_name', '').lower().strip()}_{row.get('category', '').lower().strip()}"
                existing_combinations.add(name_category_key)
    except Exception as e:
        print(f"‚ö†Ô∏è  Error reading existing combinations: {e}")

new_ingredients = []
for ingredient in ingredients:
    ...
    name_category_key = f"{ingredient_name}_{ingredient_category}"
    
    if (ingredient_url not in existing_urls and 
        name_category_key not in existing_combinations and
        ingredient_name):
        new_ingredients.append(ingredient)
        existing_combinations.add(name_category_key)  # ‚Üê‚Üê‚Üê THIS LINE IS THE PROBLEM

The BugYou are adding to existing_combinations while iterating over the current batch.That means:Ingredient 1 from batch ‚Üí not in existing ‚Üí added to new_ingredients ‚Üí key added to existing_combinations
Ingredient 2 from same batch with same name+category ‚Üí sees key already in set ‚Üí skipped

But if two different categories scrape the same ingredient (very common ‚Äî e.g., "Lavender Oil" appears in essential_oils AND cosmetic_ingredients), and they finish at similar times, both batches think it's new ‚Üí both write it.Also, the in-batch tracking (existing_combinations.add(name_category_key)) is only safe within one batch ‚Äî across batches it's redundant since the file check already covers it.The Fix (2 small changes)Remove the in-batch tracking line ‚Äî it's unnecessary and can cause false skips:

python

# REMOVE this line entirely:
# existing_combinations.add(name_category_key)  # ‚Üê delete this

Reload existing data from file BEFORE filtering (to catch writes from other categories that finished just before):

Since you're now saving once at the end, the file is consistent ‚Äî but to be 100 % safe, reload existing_urls and existing_combinations right before the final save.Move the duplicate-check logic into the final save block:python

# After collecting all_new_ingredients
if all_new_ingredients:
    print(f"üíæ Final save: Writing {len(all_new_ingredients)} new ingredients across all categories")
    
    # Re-load existing data one last time before final write
    existing_urls = set()
    existing_combinations = set()
    if target_file.exists():
        with open(target_file, 'r', newline='', encoding='utf-8') as csvfile:
            reader = csv.DictReader(csvfile)
            for row in reader:
                if row.get('url'):
                    existing_urls.add(row['url'])
                key = f"{row.get('common_name', '').lower().strip()}_{row.get('category', '').lower().strip()}"
                existing_combinations.add(key)

    # Filter again with fresh data
    final_ingredients = []
    for ingredient in all_new_ingredients:
        url = ingredient.get('url', '')
        name = ingredient.get('common_name', '').lower().strip()
        cat = ingredient.get('category', '').lower().strip()
        key = f"{name}_{cat}"
        if url not in existing_urls and key not in existing_combinations and name:
            final_ingredients.append(ingredient)

    scraper.save_ingredients_csv(final_ingredients, str(target_file))  # this now just writes (no duplicate logic needed)

And simplify save_ingredients_csv to only write (remove all duplicate checking ‚Äî it's done above).Final ResultNo race conditions
No false skips within batch
No duplicates across categories
Clean, single write

Do these changes and your CSV will be perfect.You're so close ‚Äî this is the last bug standing between you and a flawless TGSC import.Want me to paste the full corrected main() and save_ingredients_csv()? Just say go.


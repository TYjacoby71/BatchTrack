            which would cause a cartesian product.
    
            .. versionadded:: 1.4
    
            .. seealso::
    
                :ref:`change_4737`
    
        :param execution_options: Dictionary execution options which will
            be applied to all connections.  See
            :meth:`~sqlalchemy.engine.Connection.execution_options`
    
        :param future: Use the 2.0 style :class:`_engine.Engine` and
            :class:`_engine.Connection` API.
    
            As of SQLAlchemy 2.0, this parameter is present for backwards
            compatibility only and must remain at its default value of ``True``.
    
            The :paramref:`_sa.create_engine.future` parameter will be
            deprecated in a subsequent 2.x release and eventually removed.
    
            .. versionadded:: 1.4
    
            .. versionchanged:: 2.0 All :class:`_engine.Engine` objects are
               "future" style engines and there is no longer a ``future=False``
               mode of operation.
    
            .. seealso::
    
                :ref:`migration_20_toplevel`
    
        :param hide_parameters: Boolean, when set to True, SQL statement parameters
            will not be displayed in INFO logging nor will they be formatted into
            the string representation of :class:`.StatementError` objects.
    
            .. versionadded:: 1.3.8
    
            .. seealso::
    
                :ref:`dbengine_logging` - further detail on how to configure
                logging.
    
        :param implicit_returning=True:  Legacy parameter that may only be set
            to True. In SQLAlchemy 2.0, this parameter does nothing. In order to
            disable "implicit returning" for statements invoked by the ORM,
            configure this on a per-table basis using the
            :paramref:`.Table.implicit_returning` parameter.
    
    
        :param insertmanyvalues_page_size: number of rows to format into an
         INSERT statement when the statement uses "insertmanyvalues" mode, which is
         a paged form of bulk insert that is used for many backends when using
         :term:`executemany` execution typically in conjunction with RETURNING.
         Defaults to 1000, but may also be subject to dialect-specific limiting
         factors which may override this value on a per-statement basis.
    
         .. versionadded:: 2.0
    
         .. seealso::
    
            :ref:`engine_insertmanyvalues`
    
            :ref:`engine_insertmanyvalues_page_size`
    
            :paramref:`_engine.Connection.execution_options.insertmanyvalues_page_size`
    
        :param isolation_level: optional string name of an isolation level
            which will be set on all new connections unconditionally.
            Isolation levels are typically some subset of the string names
            ``"SERIALIZABLE"``, ``"REPEATABLE READ"``,
            ``"READ COMMITTED"``, ``"READ UNCOMMITTED"`` and ``"AUTOCOMMIT"``
            based on backend.
    
            The :paramref:`_sa.create_engine.isolation_level` parameter is
            in contrast to the
            :paramref:`.Connection.execution_options.isolation_level`
            execution option, which may be set on an individual
            :class:`.Connection`, as well as the same parameter passed to
            :meth:`.Engine.execution_options`, where it may be used to create
            multiple engines with different isolation levels that share a common
            connection pool and dialect.
    
            .. versionchanged:: 2.0 The
               :paramref:`_sa.create_engine.isolation_level`
               parameter has been generalized to work on all dialects which support
               the concept of isolation level, and is provided as a more succinct,
               up front configuration switch in contrast to the execution option
               which is more of an ad-hoc programmatic option.
    
            .. seealso::
    
                :ref:`dbapi_autocommit`
    
        :param json_deserializer: for dialects that support the
            :class:`_types.JSON`
            datatype, this is a Python callable that will convert a JSON string
            to a Python object.  By default, the Python ``json.loads`` function is
            used.
    
            .. versionchanged:: 1.3.7  The SQLite dialect renamed this from
               ``_json_deserializer``.
    
        :param json_serializer: for dialects that support the :class:`_types.JSON`
            datatype, this is a Python callable that will render a given object
            as JSON.   By default, the Python ``json.dumps`` function is used.
    
            .. versionchanged:: 1.3.7  The SQLite dialect renamed this from
               ``_json_serializer``.
    
    
        :param label_length=None: optional integer value which limits
            the size of dynamically generated column labels to that many
            characters. If less than 6, labels are generated as
            "_(counter)". If ``None``, the value of
            ``dialect.max_identifier_length``, which may be affected via the
            :paramref:`_sa.create_engine.max_identifier_length` parameter,
            is used instead.   The value of
            :paramref:`_sa.create_engine.label_length`
            may not be larger than that of
            :paramref:`_sa.create_engine.max_identfier_length`.
    
            .. seealso::
    
                :paramref:`_sa.create_engine.max_identifier_length`
    
        :param logging_name:  String identifier which will be used within
            the "name" field of logging records generated within the
            "sqlalchemy.engine" logger. Defaults to a hexstring of the
            object's id.
    
            .. seealso::
    
                :ref:`dbengine_logging` - further detail on how to configure
                logging.
    
                :paramref:`_engine.Connection.execution_options.logging_token`
    
        :param max_identifier_length: integer; override the max_identifier_length
            determined by the dialect.  if ``None`` or zero, has no effect.  This
            is the database's configured maximum number of characters that may be
            used in a SQL identifier such as a table name, column name, or label
            name. All dialects determine this value automatically, however in the
            case of a new database version for which this value has changed but
            SQLAlchemy's dialect has not been adjusted, the value may be passed
            here.
    
            .. versionadded:: 1.3.9
    
            .. seealso::
    
                :paramref:`_sa.create_engine.label_length`
    
        :param max_overflow=10: the number of connections to allow in
            connection pool "overflow", that is connections that can be
            opened above and beyond the pool_size setting, which defaults
            to five. this is only used with :class:`~sqlalchemy.pool.QueuePool`.
    
        :param module=None: reference to a Python module object (the module
            itself, not its string name).  Specifies an alternate DBAPI module to
            be used by the engine's dialect.  Each sub-dialect references a
            specific DBAPI which will be imported before first connect.  This
            parameter causes the import to be bypassed, and the given module to
            be used instead. Can be used for testing of DBAPIs as well as to
            inject "mock" DBAPI implementations into the :class:`_engine.Engine`.
    
        :param paramstyle=None: The `paramstyle <https://legacy.python.org/dev/peps/pep-0249/#paramstyle>`_
            to use when rendering bound parameters.  This style defaults to the
            one recommended by the DBAPI itself, which is retrieved from the
            ``.paramstyle`` attribute of the DBAPI.  However, most DBAPIs accept
            more than one paramstyle, and in particular it may be desirable
            to change a "named" paramstyle into a "positional" one, or vice versa.
            When this attribute is passed, it should be one of the values
            ``"qmark"``, ``"numeric"``, ``"named"``, ``"format"`` or
            ``"pyformat"``, and should correspond to a parameter style known
            to be supported by the DBAPI in use.
    
        :param pool=None: an already-constructed instance of
            :class:`~sqlalchemy.pool.Pool`, such as a
            :class:`~sqlalchemy.pool.QueuePool` instance. If non-None, this
            pool will be used directly as the underlying connection pool
            for the engine, bypassing whatever connection parameters are
            present in the URL argument. For information on constructing
            connection pools manually, see :ref:`pooling_toplevel`.
    
        :param poolclass=None: a :class:`~sqlalchemy.pool.Pool`
            subclass, which will be used to create a connection pool
            instance using the connection parameters given in the URL. Note
            this differs from ``pool`` in that you don't actually
            instantiate the pool in this case, you just indicate what type
            of pool to be used.
    
        :param pool_logging_name:  String identifier which will be used within
           the "name" field of logging records generated within the
           "sqlalchemy.pool" logger. Defaults to a hexstring of the object's
           id.
    
           .. seealso::
    
                :ref:`dbengine_logging` - further detail on how to configure
                logging.
    
        :param pool_pre_ping: boolean, if True will enable the connection pool
            "pre-ping" feature that tests connections for liveness upon
            each checkout.
    
            .. versionadded:: 1.2
    
            .. seealso::
    
                :ref:`pool_disconnects_pessimistic`
    
        :param pool_size=5: the number of connections to keep open
            inside the connection pool. This used with
            :class:`~sqlalchemy.pool.QueuePool` as
            well as :class:`~sqlalchemy.pool.SingletonThreadPool`.  With
            :class:`~sqlalchemy.pool.QueuePool`, a ``pool_size`` setting
            of 0 indicates no limit; to disable pooling, set ``poolclass`` to
            :class:`~sqlalchemy.pool.NullPool` instead.
    
        :param pool_recycle=-1: this setting causes the pool to recycle
            connections after the given number of seconds has passed. It
            defaults to -1, or no timeout. For example, setting to 3600
            means connections will be recycled after one hour. Note that
            MySQL in particular will disconnect automatically if no
            activity is detected on a connection for eight hours (although
            this is configurable with the MySQLDB connection itself and the
            server configuration as well).
    
            .. seealso::
    
                :ref:`pool_setting_recycle`
    
        :param pool_reset_on_return='rollback': set the
            :paramref:`_pool.Pool.reset_on_return` parameter of the underlying
            :class:`_pool.Pool` object, which can be set to the values
            ``"rollback"``, ``"commit"``, or ``None``.
    
            .. seealso::
    
                :ref:`pool_reset_on_return`
    
        :param pool_timeout=30: number of seconds to wait before giving
            up on getting a connection from the pool. This is only used
            with :class:`~sqlalchemy.pool.QueuePool`. This can be a float but is
            subject to the limitations of Python time functions which may not be
            reliable in the tens of milliseconds.
    
            .. note: don't use 30.0 above, it seems to break with the :param tag
    
        :param pool_use_lifo=False: use LIFO (last-in-first-out) when retrieving
            connections from :class:`.QueuePool` instead of FIFO
            (first-in-first-out). Using LIFO, a server-side timeout scheme can
            reduce the number of connections used during non- peak   periods of
            use.   When planning for server-side timeouts, ensure that a recycle or
            pre-ping strategy is in use to gracefully   handle stale connections.
    
              .. versionadded:: 1.3
    
              .. seealso::
    
                :ref:`pool_use_lifo`
    
                :ref:`pool_disconnects`
    
        :param plugins: string list of plugin names to load.  See
            :class:`.CreateEnginePlugin` for background.
    
            .. versionadded:: 1.2.3
    
        :param query_cache_size: size of the cache used to cache the SQL string
         form of queries.  Set to zero to disable caching.
    
         The cache is pruned of its least recently used items when its size reaches
         N * 1.5.  Defaults to 500, meaning the cache will always store at least
         500 SQL statements when filled, and will grow up to 750 items at which
         point it is pruned back down to 500 by removing the 250 least recently
         used items.
    
         Caching is accomplished on a per-statement basis by generating a
         cache key that represents the statement's structure, then generating
         string SQL for the current dialect only if that key is not present
         in the cache.   All statements support caching, however some features
         such as an INSERT with a large set of parameters will intentionally
         bypass the cache.   SQL logging will indicate statistics for each
         statement whether or not it were pull from the cache.
    
         .. note:: some ORM functions related to unit-of-work persistence as well
            as some attribute loading strategies will make use of individual
            per-mapper caches outside of the main cache.
    
    
         .. seealso::
    
            :ref:`sql_caching`
    
         .. versionadded:: 1.4
    
        :param use_insertmanyvalues: True by default, use the "insertmanyvalues"
         execution style for INSERT..RETURNING statements by default.
    
         .. versionadded:: 2.0
    
         .. seealso::
    
            :ref:`engine_insertmanyvalues`
    
        """  # noqa
    
        if "strategy" in kwargs:
            strat = kwargs.pop("strategy")
            if strat == "mock":
                # this case is deprecated
                return create_mock_engine(url, **kwargs)  # type: ignore
            else:
                raise exc.ArgumentError("unknown strategy: %r" % strat)
    
        kwargs.pop("empty_in_strategy", None)
    
        # create url.URL object
        u = _url.make_url(url)
    
        u, plugins, kwargs = u._instantiate_plugins(kwargs)
    
        entrypoint = u._get_entrypoint()
        _is_async = kwargs.pop("_is_async", False)
        if _is_async:
            dialect_cls = entrypoint.get_async_dialect_cls(u)
        else:
            dialect_cls = entrypoint.get_dialect_cls(u)
    
        if kwargs.pop("_coerce_config", False):
    
            def pop_kwarg(key: str, default: Optional[Any] = None) -> Any:
                value = kwargs.pop(key, default)
                if key in dialect_cls.engine_config_types:
                    value = dialect_cls.engine_config_types[key](value)
                return value
    
        else:
            pop_kwarg = kwargs.pop  # type: ignore
    
        dialect_args = {}
        # consume dialect arguments from kwargs
        for k in util.get_cls_kwargs(dialect_cls):
            if k in kwargs:
                dialect_args[k] = pop_kwarg(k)
    
        dbapi = kwargs.pop("module", None)
        if dbapi is None:
            dbapi_args = {}
    
            if "import_dbapi" in dialect_cls.__dict__:
                dbapi_meth = dialect_cls.import_dbapi
    
            elif hasattr(dialect_cls, "dbapi") and inspect.ismethod(
                dialect_cls.dbapi
            ):
                util.warn_deprecated(
                    "The dbapi() classmethod on dialect classes has been "
                    "renamed to import_dbapi().  Implement an import_dbapi() "
                    f"classmethod directly on class {dialect_cls} to remove this "
                    "warning; the old .dbapi() classmethod may be maintained for "
                    "backwards compatibility.",
                    "2.0",
                )
                dbapi_meth = dialect_cls.dbapi
            else:
                dbapi_meth = dialect_cls.import_dbapi
    
            for k in util.get_func_kwargs(dbapi_meth):
                if k in kwargs:
                    dbapi_args[k] = pop_kwarg(k)
            dbapi = dbapi_meth(**dbapi_args)
    
        dialect_args["dbapi"] = dbapi
    
        dialect_args.setdefault("compiler_linting", compiler.NO_LINTING)
        enable_from_linting = kwargs.pop("enable_from_linting", True)
        if enable_from_linting:
            dialect_args["compiler_linting"] ^= compiler.COLLECT_CARTESIAN_PRODUCTS
    
        for plugin in plugins:
            plugin.handle_dialect_kwargs(dialect_cls, dialect_args)
    
        # create dialect
        dialect = dialect_cls(**dialect_args)
    
        # assemble connection arguments
        (cargs_tup, cparams) = dialect.create_connect_args(u)
        cparams.update(pop_kwarg("connect_args", {}))
    
        if "async_fallback" in cparams and util.asbool(cparams["async_fallback"]):
            util.warn_deprecated(
                "The async_fallback dialect argument is deprecated and will be "
                "removed in SQLAlchemy 2.1.",
                "2.0",
            )
    
        cargs = list(cargs_tup)  # allow mutability
    
        # look for existing pool or create
        pool = pop_kwarg("pool", None)
        if pool is None:
    
            def connect(
                connection_record: Optional[ConnectionPoolEntry] = None,
            ) -> DBAPIConnection:
                if dialect._has_events:
                    for fn in dialect.dispatch.do_connect:
                        connection = cast(
                            DBAPIConnection,
                            fn(dialect, connection_record, cargs, cparams),
                        )
                        if connection is not None:
                            return connection
    
                return dialect.connect(*cargs, **cparams)
    
            creator = pop_kwarg("creator", connect)
    
            poolclass = pop_kwarg("poolclass", None)
            if poolclass is None:
                poolclass = dialect.get_dialect_pool_class(u)
            pool_args = {"dialect": dialect}
    
            # consume pool arguments from kwargs, translating a few of
            # the arguments
            for k in util.get_cls_kwargs(poolclass):
                tk = _pool_translate_kwargs.get(k, k)
                if tk in kwargs:
                    pool_args[k] = pop_kwarg(tk)
    
            for plugin in plugins:
                plugin.handle_pool_kwargs(poolclass, pool_args)
    
            pool = poolclass(creator, **pool_args)
        else:
            pool._dialect = dialect
    
        if (
            hasattr(pool, "_is_asyncio")
            and pool._is_asyncio is not dialect.is_async
        ):
            raise exc.ArgumentError(
                f"Pool class {pool.__class__.__name__} cannot be "
                f"used with {'non-' if not dialect.is_async else ''}"
                "asyncio engine",
                code="pcls",
            )
    
        # create engine.
        if not pop_kwarg("future", True):
            raise exc.ArgumentError(
                "The 'future' parameter passed to "
                "create_engine() may only be set to True."
            )
    
        engineclass = base.Engine
    
        engine_args = {}
        for k in util.get_cls_kwargs(engineclass):
            if k in kwargs:
                engine_args[k] = pop_kwarg(k)
    
        # internal flags used by the test suite for instrumenting / proxying
        # engines with mocks etc.
        _initialize = kwargs.pop("_initialize", True)
    
        # all kwargs should be consumed
        if kwargs:
>           raise TypeError(
                "Invalid argument(s) %s sent to create_engine(), "
                "using configuration %s/%s/%s.  Please check that the "
                "keyword arguments are appropriate for this combination "
                "of components."
                % (
                    ",".join("'%s'" % k for k in kwargs),
                    dialect.__class__.__name__,
                    pool.__class__.__name__,
                    engineclass.__name__,
                )
            )
E           TypeError: Invalid argument(s) 'pool_size','max_overflow' sent to create_engine(), using configuration SQLiteDialect_pysqlite/StaticPool/Engine.  Please check that the keyword arguments are appropriate for this combination of components.

.pythonlibs/lib/python3.11/site-packages/sqlalchemy/engine/create.py:700: TypeError
__________________________________________ ERROR at setup of test_pos_sale_uses_canonical_service ___________________________________________
file /home/runner/workspace/tests/test_pos_integration_canonicalization.py, line 9
  def test_pos_sale_uses_canonical_service(app, db_session):
E       fixture 'db_session' not found
>       available fixtures: app, auth_headers, cache, capfd, capfdbinary, caplog, capsys, capsysbinary, client, doctest_namespace, monkeypatch, pytestconfig, record_property, record_testsuite_property, record_xml_attribute, recwarn, runner, tmp_path, tmp_path_factory, tmpdir, tmpdir_factory
>       use 'pytest --fixtures [testpath]' for help on them.

/home/runner/workspace/tests/test_pos_integration_canonicalization.py:9
------------------------------------------------------------ Captured log setup -------------------------------------------------------------
INFO     app:unit_utils.py:20 BatchTrack startup
================================================================= FAILURES ==================================================================
_____________________________________________ test_api_reservation_routes_uses_canonical_audit ______________________________________________

app = <Flask 'app'>

    def test_api_reservation_routes_uses_canonical_audit(app):
        """Test that API reservation routes use canonical audit helper"""
        with app.app_context():
            with patch('app.services.inventory_adjustment.record_audit_entry') as mock_audit:
    
                # Mock the route function that writes audit entries
>               from app.blueprints.api.reservation_routes import _write_unreserved_audit
E               ImportError: cannot import name '_write_unreserved_audit' from 'app.blueprints.api.reservation_routes' (/home/runner/workspace/app/blueprints/api/reservation_routes.py)

tests/test_audit_canonicalization.py:12: ImportError
------------------------------------------------------------ Captured log setup -------------------------------------------------------------
INFO     app:unit_utils.py:20 BatchTrack startup
_________________________________________________ test_products_routes_uses_canonical_audit _________________________________________________

app = <Flask 'app'>

    def test_products_routes_uses_canonical_audit(app):
        """Test that product creation uses canonical audit helper"""
        with app.app_context():
            with patch('app.services.inventory_adjustment.record_audit_entry') as mock_audit:
    
                # Mock the route function that writes audit entries
>               from app.blueprints.products.products import _write_product_created_audit
E               ImportError: cannot import name '_write_product_created_audit' from 'app.blueprints.products.products' (/home/runner/workspace/app/blueprints/products/products.py)

tests/test_audit_canonicalization.py:34: ImportError
------------------------------------------------------------ Captured log setup -------------------------------------------------------------
INFO     app:unit_utils.py:20 BatchTrack startup
_______________________________ TestExpirationCanonicalService.test_mark_fifo_expired_calls_canonical_service _______________________________

args = (<tests.test_expiration_canonicalization.TestExpirationCanonicalService object at 0x7f3fbc7a1610>,), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/contextlib.py:137: in __enter__
    return next(self.gen)
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1357: in decoration_helper
    arg = exit_stack.enter_context(patching)
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/contextlib.py:517: in enter_context
    result = _enter(cm)
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7f3fbcb4fa10>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'app.blueprints.expiration.services' from '/home/runner/workspace/app/blueprints/expiration/services.py'> does not have the attribute 'process_inventory_adjustment'

/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________________ TestExpirationCanonicalService.test_mark_product_expired_calls_canonical_service ______________________________

args = (<tests.test_expiration_canonicalization.TestExpirationCanonicalService object at 0x7f3fbc7a1c90>,), keywargs = {}

    @wraps(func)
    def patched(*args, **keywargs):
>       with self.decoration_helper(patched,
                                    args,
                                    keywargs) as (newargs, newkeywargs):

/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1375: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/contextlib.py:137: in __enter__
    return next(self.gen)
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1357: in decoration_helper
    arg = exit_stack.enter_context(patching)
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/contextlib.py:517: in enter_context
    result = _enter(cm)
/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1446: in __enter__
    original, local = self.get_original()
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <unittest.mock._patch object at 0x7f3fbcb4fc10>

    def get_original(self):
        target = self.getter()
        name = self.attribute
    
        original = DEFAULT
        local = False
    
        try:
            original = target.__dict__[name]
        except (AttributeError, KeyError):
            original = getattr(target, name, DEFAULT)
        else:
            local = True
    
        if name in _builtins and isinstance(target, ModuleType):
            self.create = True
    
        if not self.create and original is DEFAULT:
>           raise AttributeError(
                "%s does not have the attribute %r" % (target, name)
            )
E           AttributeError: <module 'app.blueprints.expiration.services' from '/home/runner/workspace/app/blueprints/expiration/services.py'> does not have the attribute 'process_inventory_adjustment'

/nix/store/7d088dip86hlzri9sk0h78b63yfmx0a0-python3-3.11.13/lib/python3.11/unittest/mock.py:1419: AttributeError
_____________________________ TestPOSIntegrationCanonicalService.test_reserve_inventory_calls_canonical_service _____________________________

item_id = 1, quantity = 5.0, order_id = 'ORD-123', source = 'shopify', notes = 'Test reservation', sale_price = None, expires_in_hours = None

    @staticmethod
    def reserve_inventory(item_id: int, quantity: float, order_id: str, source: str = "shopify",
                         notes: str = None, sale_price: float = None, expires_in_hours: int = None) -> tuple[bool, str]:
        """
        Reserve inventory using new reservation model - acts like regular deduction
        Args:
            item_id: Inventory item ID (product type)
            quantity: Quantity to reserve
            order_id: Order identifier (required)
            source: Source system ("shopify", "manual", etc.)
            notes: Optional notes
            sale_price: Expected sale price
            expires_in_hours: Hours until reservation expires
    
        Returns:
            (success, message)
        """
        try:
            # Get the original inventory item
            original_item = InventoryItem.query.get(item_id)
            if not original_item or original_item.type != 'product':
                return False, "Product item not found"
    
            # Check if we have enough available inventory (ignoring expired lots)
            available = original_item.available_quantity  # This should exclude expired
            if available < quantity:
                return False, f"Insufficient inventory. Available: {available}, Requested: {quantity}"
    
            # Get or create the reserved inventory item
            reserved_item_name = f"{original_item.name} (Reserved)"
            reserved_item = InventoryItem.query.filter_by(
                name=reserved_item_name,
                type='product-reserved',
                organization_id=original_item.organization_id
            ).first()
    
            if not reserved_item:
                # Create new reserved inventory item
                reserved_item = InventoryItem(
                    name=reserved_item_name,
                    type='product-reserved',
                    unit=original_item.unit,
                    cost_per_unit=original_item.cost_per_unit,
                    quantity=0.0,
                    organization_id=original_item.organization_id,
                    category_id=original_item.category_id,
                    is_perishable=original_item.is_perishable,
                    shelf_life_days=original_item.shelf_life_days
                )
                db.session.add(reserved_item)
                db.session.flush()
    
            # Get the source FIFO entry for tracking
            fifo_entries = FIFOService.get_fifo_entries(item_id)
            source_fifo_id = None
            source_batch_id = None
    
            if fifo_entries:
                # Use the oldest available entry for reference
                oldest_entry = fifo_entries[0]
                source_fifo_id = oldest_entry.id
                source_batch_id = getattr(oldest_entry, 'batch_id', None)
    
            # 1. DEDUCT from original item using regular FIFO (no remaining_quantity tracking)
            deduction_success = process_inventory_adjustment(
                item_id=item_id,
                quantity=quantity,
                change_type='reserved',
                notes=f"Reserved for order {order_id} ({source}). {notes or ''}",
                order_id=order_id,
                created_by=current_user.id if current_user.is_authenticated else None
            )
    
            if not deduction_success:
                return False, "Failed to deduct from available inventory"
    
            # 2. CREATE reservation line item (this is now the source of truth)
            expires_at = None
            if expires_in_hours:
                expires_at = datetime.utcnow() + timedelta(hours=expires_in_hours)
    
            reservation = Reservation(
                order_id=order_id,
                product_item_id=item_id,
                reserved_item_id=reserved_item.id,
                quantity=quantity,
                unit=original_item.unit,
                unit_cost=original_item.cost_per_unit,
                sale_price=sale_price,
                source_fifo_id=source_fifo_id,
                source_batch_id=source_batch_id,
                source=source,
                expires_at=expires_at,
                notes=notes,
                created_by=current_user.id if current_user.is_authenticated else None,
                organization_id=current_user.organization_id if current_user.is_authenticated else original_item.organization_id
            )
>           db.session.add(reservation)
E           AttributeError: 'MockDBSession' object has no attribute 'session'

app/services/pos_integration.py:114: AttributeError

During handling of the above exception, another exception occurred:

self = <tests.test_pos_integration_canonicalization.TestPOSIntegrationCanonicalService object at 0x7f3fbc1bc810>
mock_user = <MagicMock name='current_user' id='139911661604880'>, mock_reservation = <MagicMock name='Reservation' id='139911660842128'>
mock_item = <MagicMock name='InventoryItem' id='139911661589008'>
mock_process = <MagicMock name='process_inventory_adjustment' id='139911661587792'>

    @patch('app.services.pos_integration.process_inventory_adjustment')
    @patch('app.services.pos_integration.InventoryItem')
    @patch('app.services.pos_integration.Reservation')
    @patch('app.services.pos_integration.current_user')
    def test_reserve_inventory_calls_canonical_service(self, mock_user, mock_reservation, mock_item, mock_process):
        """Test that inventory reservation calls process_inventory_adjustment"""
        # Mock the original inventory item
        mock_original_item = MagicMock()
        mock_original_item.id = 1
        mock_original_item.name = "Test Product"
        mock_original_item.type = 'product'
        mock_original_item.unit = 'piece'
        mock_original_item.cost_per_unit = 10.0
        mock_original_item.available_quantity = 50.0
        mock_original_item.organization_id = 1
    
        # Mock reserved item
        mock_reserved_item = MagicMock()
        mock_reserved_item.id = 2
        mock_reserved_item.quantity = 0.0
    
        mock_item.query.get.return_value = mock_original_item
        mock_item.query.filter_by.return_value.first.return_value = mock_reserved_item
    
        mock_user.id = 1
        mock_user.is_authenticated = True
        mock_user.organization_id = 1
    
        # Mock process_inventory_adjustment to succeed
        mock_process.return_value = True
    
        # Call the service
>       success, message = POSIntegrationService.reserve_inventory(
            item_id=1,
            quantity=5.0,
            order_id="ORD-123",
            source="shopify",
            notes="Test reservation"
        )

tests/test_pos_integration_canonicalization.py:83: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

item_id = 1, quantity = 5.0, order_id = 'ORD-123', source = 'shopify', notes = 'Test reservation', sale_price = None, expires_in_hours = None

    @staticmethod
    def reserve_inventory(item_id: int, quantity: float, order_id: str, source: str = "shopify",
                         notes: str = None, sale_price: float = None, expires_in_hours: int = None) -> tuple[bool, str]:
        """
        Reserve inventory using new reservation model - acts like regular deduction
        Args:
            item_id: Inventory item ID (product type)
            quantity: Quantity to reserve
            order_id: Order identifier (required)
            source: Source system ("shopify", "manual", etc.)
            notes: Optional notes
            sale_price: Expected sale price
            expires_in_hours: Hours until reservation expires
    
        Returns:
            (success, message)
        """
        try:
            # Get the original inventory item
            original_item = InventoryItem.query.get(item_id)
            if not original_item or original_item.type != 'product':
                return False, "Product item not found"
    
            # Check if we have enough available inventory (ignoring expired lots)
            available = original_item.available_quantity  # This should exclude expired
            if available < quantity:
                return False, f"Insufficient inventory. Available: {available}, Requested: {quantity}"
    
            # Get or create the reserved inventory item
            reserved_item_name = f"{original_item.name} (Reserved)"
            reserved_item = InventoryItem.query.filter_by(
                name=reserved_item_name,
                type='product-reserved',
                organization_id=original_item.organization_id
            ).first()
    
            if not reserved_item:
                # Create new reserved inventory item
                reserved_item = InventoryItem(
                    name=reserved_item_name,
                    type='product-reserved',
                    unit=original_item.unit,
                    cost_per_unit=original_item.cost_per_unit,
                    quantity=0.0,
                    organization_id=original_item.organization_id,
                    category_id=original_item.category_id,
                    is_perishable=original_item.is_perishable,
                    shelf_life_days=original_item.shelf_life_days
                )
                db.session.add(reserved_item)
                db.session.flush()
    
            # Get the source FIFO entry for tracking
            fifo_entries = FIFOService.get_fifo_entries(item_id)
            source_fifo_id = None
            source_batch_id = None
    
            if fifo_entries:
                # Use the oldest available entry for reference
                oldest_entry = fifo_entries[0]
                source_fifo_id = oldest_entry.id
                source_batch_id = getattr(oldest_entry, 'batch_id', None)
    
            # 1. DEDUCT from original item using regular FIFO (no remaining_quantity tracking)
            deduction_success = process_inventory_adjustment(
                item_id=item_id,
                quantity=quantity,
                change_type='reserved',
                notes=f"Reserved for order {order_id} ({source}). {notes or ''}",
                order_id=order_id,
                created_by=current_user.id if current_user.is_authenticated else None
            )
    
            if not deduction_success:
                return False, "Failed to deduct from available inventory"
    
            # 2. CREATE reservation line item (this is now the source of truth)
            expires_at = None
            if expires_in_hours:
                expires_at = datetime.utcnow() + timedelta(hours=expires_in_hours)
    
            reservation = Reservation(
                order_id=order_id,
                product_item_id=item_id,
                reserved_item_id=reserved_item.id,
                quantity=quantity,
                unit=original_item.unit,
                unit_cost=original_item.cost_per_unit,
                sale_price=sale_price,
                source_fifo_id=source_fifo_id,
                source_batch_id=source_batch_id,
                source=source,
                expires_at=expires_at,
                notes=notes,
                created_by=current_user.id if current_user.is_authenticated else None,
                organization_id=current_user.organization_id if current_user.is_authenticated else original_item.organization_id
            )
            db.session.add(reservation)
    
            # 3. UPDATE reserved item quantity (for display purposes)
            reserved_item.quantity += quantity
    
            # 4. LOG the reservation using canonical inventory adjustment
            allocation_success = process_inventory_adjustment(
                item_id=reserved_item.id,
                quantity=quantity,
                change_type='reserved_allocation',
                unit=original_item.unit,
                notes=f"Reserved for order {order_id}. {notes or ''}",
                created_by=current_user.id if current_user.is_authenticated else None,
                cost_override=original_item.cost_per_unit
            )
    
            if not allocation_success:
                return False, "Failed to log reservation allocation"
    
            db.session.commit()
            return True, f"Reserved {quantity} units for order {order_id}"
    
        except Exception as e:
>           db.session.rollback()
E           AttributeError: 'MockDBSession' object has no attribute 'session'

app/services/pos_integration.py:137: AttributeError
__________________________________________ test_credit_specific_lot_called_on_reservation_release ___________________________________________

app = <Flask 'app'>

    def test_credit_specific_lot_called_on_reservation_release(app):
        """Test that releasing a reservation calls the canonical credit_specific_lot helper"""
        with app.app_context():
            with patch('app.services.inventory_adjustment.credit_specific_lot') as mock_credit:
                mock_credit.return_value = True
    
                # Mock reservation object
                mock_reservation = MagicMock()
                mock_reservation.inventory_item_id = 123
                mock_reservation.source_fifo_id = 456
                mock_reservation.quantity = 5.0
    
                # Mock source entry
                mock_source_entry = MagicMock()
                mock_source_entry.unit = "kg"
    
                with patch('app.models.inventory.InventoryHistory.query') as mock_query:
                    mock_query.get.return_value = mock_source_entry
    
                    # This should trigger the credit_specific_lot call
>                   ReservationService._release_reservation_inventory(mock_reservation, mock_source_entry)
E                   AttributeError: type object 'ReservationService' has no attribute '_release_reservation_inventory'

tests/test_reservation_canonicalization.py:27: AttributeError
------------------------------------------------------------ Captured log setup -------------------------------------------------------------
INFO     app:unit_utils.py:20 BatchTrack startup
____________________________________________ test_record_audit_entry_called_for_unreserved_audit ____________________________________________

app = <Flask 'app'>

    def test_record_audit_entry_called_for_unreserved_audit(app):
        """Test that audit entries use the canonical record_audit_entry helper"""
        with app.app_context():
            with patch('app.services.inventory_adjustment.record_audit_entry') as mock_audit:
    
                # Mock reservation object
                mock_reservation = MagicMock()
                mock_reservation.inventory_item_id = 123
                mock_reservation.source_fifo_id = 456
                mock_reservation.id = 789
    
                # This should trigger the record_audit_entry call
>               ReservationService._write_unreserved_audit_entry(mock_reservation)
E               AttributeError: type object 'ReservationService' has no attribute '_write_unreserved_audit_entry'

tests/test_reservation_canonicalization.py:51: AttributeError
------------------------------------------------------------ Captured log setup -------------------------------------------------------------
INFO     app:unit_utils.py:20 BatchTrack startup
============================================================= warnings summary ==============================================================
tests/test_audit_canonicalization.py: 2 warnings
tests/test_expiration_canonicalization.py: 1 warning
tests/test_google_oauth.py: 7 warnings
tests/test_inventory_fifo.py: 3 warnings
tests/test_inventory_routes_canonicalization.py: 1 warning
tests/test_pos_integration_canonicalization.py: 1 warning
tests/test_product_sku.py: 4 warnings
tests/test_reservation_canonicalization.py: 2 warnings
tests/test_signup_tiers.py: 5 warnings
tests/test_stripe_webhooks.py: 4 warnings
  /home/runner/workspace/.pythonlibs/lib/python3.11/site-packages/flask_limiter/extension.py:333: UserWarning: Using the in-memory storage for tracking rate limits as no storage was explicitly specified. This is not recommended for production use. See: https://flask-limiter.readthedocs.io#configuring-a-storage-backend for documentation about configuring the storage backend.
    warnings.warn(

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
========================================================== short test summary info ==========================================================
FAILED tests/test_audit_canonicalization.py::test_api_reservation_routes_uses_canonical_audit - ImportError: cannot import name '_write_unreserved_audit' from 'app.blueprints.api.reservation_routes' (/home/runner/workspace/app/bluep...
FAILED tests/test_audit_canonicalization.py::test_products_routes_uses_canonical_audit - ImportError: cannot import name '_write_product_created_audit' from 'app.blueprints.products.products' (/home/runner/workspace/app/bluep...
FAILED tests/test_expiration_canonicalization.py::TestExpirationCanonicalService::test_mark_fifo_expired_calls_canonical_service - AttributeError: <module 'app.blueprints.expiration.services' from '/home/runner/workspace/app/blueprints/expiration/services.py'> does n...
FAILED tests/test_expiration_canonicalization.py::TestExpirationCanonicalService::test_mark_product_expired_calls_canonical_service - AttributeError: <module 'app.blueprints.expiration.services' from '/home/runner/workspace/app/blueprints/expiration/services.py'> does n...
FAILED tests/test_pos_integration_canonicalization.py::TestPOSIntegrationCanonicalService::test_reserve_inventory_calls_canonical_service - AttributeError: 'MockDBSession' object has no attribute 'session'
FAILED tests/test_reservation_canonicalization.py::test_credit_specific_lot_called_on_reservation_release - AttributeError: type object 'ReservationService' has no attribute '_release_reservation_inventory'
FAILED tests/test_reservation_canonicalization.py::test_record_audit_entry_called_for_unreserved_audit - AttributeError: type object 'ReservationService' has no attribute '_write_unreserved_audit_entry'
ERROR tests/test_expiration_canonicalization.py::test_expiration_service_uses_canonical_adjustment
ERROR tests/test_inventory_fifo.py::TestInventoryFIFOCharacterization::test_single_entry_point_exists
ERROR tests/test_inventory_fifo.py::TestInventoryFIFOCharacterization::test_fifo_deduction_order
ERROR tests/test_inventory_fifo.py::TestInventoryFIFOCharacterization::test_inventory_adjustment_delegates_properly
ERROR tests/test_inventory_routes_canonicalization.py::test_recount_adjustment_uses_canonical_service
ERROR tests/test_inventory_routes_canonicalization.py::TestInventoryRoutesCanonicalService::test_adjust_inventory_initial_stock_calls_canonical_service - TypeError: Invalid argument(s) 'pool_size','max_overflow' sent to create_engine(), using configuration SQLiteDialect_pysqlite/StaticPool...
ERROR tests/test_pos_integration_canonicalization.py::test_pos_sale_uses_canonical_service
=========================================== 7 failed, 20 passed, 30 warnings, 7 errors in 33.22s ============================================

You’re not missing “mystery commands” — but you are bypassing the runner and (likely) running an older Stage‑1 implementation, which makes it look like you processed 17k while only matching ~158.

What should happen (A→Z)
By the time PubChem runs, the DB should already contain:

source_items (with CAS/INCI pulled from CosIng/TGSC rows)
merged_item_forms (with cas_numbers_json aggregated)
normalized_terms …and PubChem Stage 1 should match primarily via CAS when present (high match rate).
The missing piece in what you ran
You ran only this:

pubchem_pipeline.stage_and_match_items(limit=current_batch)
That does not guarantee you’re using the “account config” and it can misreport progress if you’re on an older version where:

scanned counts rows iterated, not rows actually processed, and
you end up incrementing “processed” while mostly skipping already-seen rows → very low match count vs huge processed count.
That exact bug is why you can see “17k processed” but only ~158 matched.

The correct “account-style” commands (no custom Python loop)
Run these instead, with the branch code you pushed (cursor/seeding-file-organization-3fb1):

1) Deterministic ingestion (must be run first)
export COMPILER_DB_PATH="data_builder/ingredients/output/Final DB.db"
python3 -m data_builder.ingredients.run_ingestion_pipeline
2) PubChem Stage 1 — match ONLY (repeat until it says scanned=0)
export PUBCHEM_WORKERS=16
python3 -m data_builder.ingredients.run_pubchem_pipeline --mode match_only --match-limit 5000 --term-match-limit 0
Keep running that exact command until it reports scanned: 0 (meaning no unprocessed items remain).

3) PubChem Stage 2 — fetch/cache ONLY (after Stage 1 is complete)
python3 -m data_builder.ingredients.run_pubchem_pipeline --mode fetch_only --batch-size 100
4) Apply ONLY
python3 -m data_builder.ingredients.run_pubchem_pipeline --mode apply_only --apply-limit 0 --term-apply-limit 0
Why you expected “6000+ matches”
That expectation is reasonable only if your merged_item_forms have thousands of CAS-bearing rows and Stage 1 is actually using them. With the correct runner + correct stage-1 implementation, you’ll see match counts climb quickly on CAS-heavy portions.

If you want one quick confirmation that you’re missing the ingestion→CAS propagation: run this single query in prod and paste the output:

python3 - <<'PY'
import sqlite3
db="data_builder/ingredients/output/Final DB.db"
con=sqlite3.connect(db)
cur=con.cursor()
cur.execute("select count(*) from merged_item_forms")
print("merged_item_forms:", cur.fetchone()[0])
cur.execute("select count(*) from merged_item_forms where cas_numbers_json not in ('', '[]') and cas_numbers_json is not null")
print("item_forms_with_cas:", cur.fetchone()[0])
PY
If item_forms_with_cas is low, you won’t get 6000 matches no matter what; if it’s high, then your low match count is from the Stage‑1 progress/matching path you used.

there is only suposed to be one path. what are you taking about?
You’re right: there should be one path.

What I’m saying is: you didn’t run the one canonical path—you ran an ad‑hoc Python loop that calls pubchem_pipeline.stage_and_match_items() directly. That bypasses the canonical runner and can use behavior/config that doesn’t match the intended “account” flow.

The one path (canonical)
Run these commands only (items-only PubChem), in this order:

export COMPILER_DB_PATH="data_builder/ingredients/output/Final DB.db"
 
# 1) Ingest (CosIng + TGSC → DB + merged items + queue)
python3 -m data_builder.ingredients.run_ingestion_pipeline
 
# 2) PubChem Stage 1 (match-only) — repeat until scanned=0
export PUBCHEM_WORKERS=16
python3 -m data_builder.ingredients.run_pubchem_pipeline --mode match_only --match-limit 5000 --term-match-limit 0
 
# 3) PubChem Stage 2 (fetch/cache)
python3 -m data_builder.ingredients.run_pubchem_pipeline --mode fetch_only --batch-size 100
 
# 4) Apply PubChem to items (fill-only)
python3 -m data_builder.ingredients.run_pubchem_pipeline --mode apply_only --apply-limit 0 --term-apply-limit 0
That’s the single A→Z deterministic path up through PubChem enrichment.

If you ran something else (like python3 <<EOF ... pubchem_pipeline.stage_and_match_items ... EOF), that’s a different path, and it’s why you’re seeing confusing numbers like “17k processed but 158 matched.”